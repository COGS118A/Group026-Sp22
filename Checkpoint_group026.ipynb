{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Pelé\n",
    "- Diego Maradonna\n",
    "- Johan Cruyff\n",
    "- Roberto Carlos\n",
    "- Franz Beckenbaur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "UPDATED FROM PROPOSAL!\n",
    "\n",
    "You should have obtained and cleaned (if necessary) data you will use for this project.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is 120 breeds of dogs with pictures of each, as well as annotations for each image if we chose to use those. With 20k pictures we believe we can use the pixel data from each image to develop features to do a classification problem\n",
    "\n",
    "**Dataset Stats**  \n",
    "Total Pics: 20,580  \n",
    "Total Species: 120\n",
    "\n",
    "Average # pics: \t 171.5  \n",
    "Minimum # pics: \t 148  \n",
    "Maximum # pics: \t 252  \n",
    "\n",
    "**Image Stats**  \n",
    "Mean img Height: \t 385.861  \n",
    "Mean img Width: \t 442.532  \n",
    "\n",
    "Med img Height: \t 375.0  \n",
    "Med img Width: \t\t 500.0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output.png](output.png)\n",
    "*There are no low outliers (too little info), only breeds with a relatively large amount of pics*\n",
    "![output2.png](output2.png)\n",
    "*even the lowest 50 breeds have a range of 8 images, little to no underrepresentation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['silky_terrier',\n",
       "  'Scottish_deerhound',\n",
       "  'Chesapeake_Bay_retriever',\n",
       "  'Ibizan_hound',\n",
       "  'haired_fox_terrier',\n",
       "  'Saluki',\n",
       "  'cocker_spaniel',\n",
       "  'schipperke',\n",
       "  'borzoi',\n",
       "  'Pembroke',\n",
       "  'komondor',\n",
       "  'Staffordshire_bullterrier',\n",
       "  'standard_poodle',\n",
       "  'Eskimo_dog',\n",
       "  'English_foxhound',\n",
       "  'golden_retriever',\n",
       "  'Sealyham_terrier',\n",
       "  'Japanese_spaniel',\n",
       "  'miniature_schnauzer',\n",
       "  'malamute',\n",
       "  'malinois',\n",
       "  'Pekinese',\n",
       "  'giant_schnauzer',\n",
       "  'Mexican_hairless',\n",
       "  'Doberman',\n",
       "  'standard_schnauzer',\n",
       "  'dhole',\n",
       "  'German_shepherd',\n",
       "  'Bouvier_des_Flandres',\n",
       "  'Siberian_husky',\n",
       "  'Norwich_terrier',\n",
       "  'Irish_terrier',\n",
       "  'Norfolk_terrier',\n",
       "  'Saint_Bernard',\n",
       "  'Border_terrier',\n",
       "  'briard',\n",
       "  'Tibetan_mastiff',\n",
       "  'bull_mastiff',\n",
       "  'Maltese_dog',\n",
       "  'Kerry_blue_terrier',\n",
       "  'kuvasz',\n",
       "  'Greater_Swiss_Mountain_dog',\n",
       "  'Lakeland_terrier',\n",
       "  'Blenheim_spaniel',\n",
       "  'basset',\n",
       "  'West_Highland_white_terrier',\n",
       "  'Chihuahua',\n",
       "  'Border_collie',\n",
       "  'redbone',\n",
       "  'Irish_wolfhound',\n",
       "  'bluetick',\n",
       "  'miniature_poodle',\n",
       "  'Cardigan',\n",
       "  'EntleBucher',\n",
       "  'Norwegian_elkhound',\n",
       "  'haired_pointer',\n",
       "  'Bernese_mountain_dog',\n",
       "  'papillon',\n",
       "  'Tibetan_terrier',\n",
       "  'Gordon_setter',\n",
       "  'American_Staffordshire_terrier',\n",
       "  'vizsla',\n",
       "  'kelpie',\n",
       "  'Weimaraner',\n",
       "  'miniature_pinscher',\n",
       "  'boxer',\n",
       "  'chow',\n",
       "  'Old_English_sheepdog',\n",
       "  'pug',\n",
       "  'Rhodesian_ridgeback',\n",
       "  'Scotch_terrier',\n",
       "  'Tzu',\n",
       "  'affenpinscher',\n",
       "  'whippet',\n",
       "  'Sussex_spaniel',\n",
       "  'otterhound',\n",
       "  'coated_retriever',\n",
       "  'English_setter',\n",
       "  'Italian_greyhound',\n",
       "  'Labrador_retriever',\n",
       "  'collie',\n",
       "  'cairn',\n",
       "  'Rottweiler',\n",
       "  'Australian_terrier',\n",
       "  'toy_terrier',\n",
       "  'Shetland_sheepdog',\n",
       "  'African_hunting_dog',\n",
       "  'Newfoundland',\n",
       "  'Walker_hound',\n",
       "  'Lhasa',\n",
       "  'beagle',\n",
       "  'Samoyed',\n",
       "  'Great_Dane',\n",
       "  'Airedale',\n",
       "  'bloodhound',\n",
       "  'Irish_setter',\n",
       "  'keeshond',\n",
       "  'Dandie_Dinmont',\n",
       "  'basenji',\n",
       "  'Bedlington_terrier',\n",
       "  'Appenzeller',\n",
       "  'clumber',\n",
       "  'toy_poodle',\n",
       "  'Great_Pyrenees',\n",
       "  'English_springer',\n",
       "  'Afghan_hound',\n",
       "  'Brittany_spaniel',\n",
       "  'Welsh_springer_spaniel',\n",
       "  'Boston_bull',\n",
       "  'dingo',\n",
       "  'coated_wheaten_terrier',\n",
       "  'coated_retriever',\n",
       "  'French_bulldog',\n",
       "  'Irish_water_spaniel',\n",
       "  'Pomeranian',\n",
       "  'Brabancon_griffon',\n",
       "  'Yorkshire_terrier',\n",
       "  'groenendael',\n",
       "  'Leonberg',\n",
       "  'tan_coonhound'],\n",
       " 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = str(Path.cwd())+'/Images'\n",
    "all_img_dir = [i for i in os.listdir(directory) if 'n0' in i]\n",
    "\n",
    "Name = []\n",
    "for file in all_img_dir: \n",
    "    name = file.split('-')[-1]\n",
    "    Name += [name]\n",
    "Name, len(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(color_mode='rgb', target_size=(128, 128)):\n",
    "    train_data = [] #np.array([])\n",
    "    test_data = [] #np.array([])\n",
    "    train_label = [] #np.array([]) \n",
    "    test_label = [] #np.array([])\n",
    "\n",
    "    for i in range(len(Name)):\n",
    "        path = os.path.join(directory+'/', all_img_dir[i])\n",
    "\n",
    "        t = 0\n",
    "        for im in os.listdir(path):\n",
    "            n = len(os.listdir(path))\n",
    "            image = load_img(os.path.join(path+'/', im), \n",
    "                             color_mode=color_mode, #grayscale=False,  \n",
    "                             target_size=target_size)\n",
    "            image = img_to_array(image)\n",
    "            image = image/255.0\n",
    "            \n",
    "            if t <= np.floor(n*0.8):\n",
    "                train_data.append(image)\n",
    "                train_label.append(Name[i])          \n",
    "            else:\n",
    "                test_data.append(image)\n",
    "                test_label.append(Name[i])\n",
    "        \n",
    "            t+=1\n",
    "    \n",
    "    return train_data, test_data, train_label, test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dog images in grayscale and sizes of 50 x 50 \n",
    "\n",
    "train_data, test_data, train_label, test_label = load_image(color_mode='grayscale',\n",
    "                                                            target_size=(50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is now: (16538, 2500)\n",
      "test  shape is now: (4042, 2500)\n"
     ]
    }
   ],
   "source": [
    "# convert image data into numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "# flatten each image into 1-D array of pixel values\n",
    "train_data = train_data.reshape(-1, train_data.shape[0]).T\n",
    "test_data = test_data.reshape(-1, test_data.shape[0]).T\n",
    "\n",
    "# get image labels\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "# Let's print out the new shape\n",
    "print('train shape is now: ' + str(train_data.shape))\n",
    "print('test  shape is now: ' + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data and labels into pandas dataframe\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df['label'] = train_label\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['label'] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.313726</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.313726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16533</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16534</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16535</th>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16536</th>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16537</th>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16538 rows × 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.850980  0.125490  0.247059  0.639216  0.403922  0.317647  0.329412   \n",
       "1      0.847059  0.203922  0.207843  0.725490  0.396078  0.176471  0.258824   \n",
       "2      0.831373  0.003922  0.105882  0.443137  0.384314  0.619608  0.466667   \n",
       "3      0.776471  0.670588  0.215686  0.564706  0.388235  0.239216  0.513726   \n",
       "4      0.741176  0.447059  0.160784  0.741176  0.388235  0.333333  0.454902   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16533  0.003922  0.274510  0.694118  0.443137  0.474510  0.835294  0.490196   \n",
       "16534  0.003922  0.407843  0.654902  0.525490  0.219608  0.768627  0.760784   \n",
       "16535  0.031373  0.176471  0.670588  0.270588  0.682353  0.682353  0.505882   \n",
       "16536  0.011765  0.152941  0.658824  0.427451  0.372549  0.635294  0.654902   \n",
       "16537  0.113725  0.286275  0.654902  0.415686  0.333333  0.454902  0.662745   \n",
       "\n",
       "              7         8         9  ...      2491      2492      2493  \\\n",
       "0      0.345098  0.658824  0.349020  ...  0.105882  0.690196  0.164706   \n",
       "1      0.458824  0.490196  0.333333  ...  0.098039  0.670588  0.101961   \n",
       "2      0.392157  0.525490  0.325490  ...  0.082353  0.666667  0.113725   \n",
       "3      0.309804  0.364706  0.337255  ...  0.094118  0.678431  0.121569   \n",
       "4      0.231373  0.388235  0.313726  ...  0.113725  0.917647  0.141176   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "16533  0.858824  0.207843  0.650980  ...  0.694118  0.121569  0.403922   \n",
       "16534  0.635294  0.878431  0.933333  ...  0.698039  0.101961  0.294118   \n",
       "16535  0.611765  0.411765  0.941176  ...  0.666667  0.109804  0.333333   \n",
       "16536  0.349020  0.360784  0.937255  ...  0.686275  0.152941  0.654902   \n",
       "16537  0.196078  0.717647  0.941176  ...  0.654902  0.164706  0.309804   \n",
       "\n",
       "           2494      2495      2496      2497      2498      2499  \\\n",
       "0      0.349020  0.819608  0.988235  0.090196  0.376471  0.368627   \n",
       "1      0.588235  0.839216  0.988235  0.152941  0.396078  0.145098   \n",
       "2      0.313726  0.760784  0.203922  0.141176  0.498039  0.105882   \n",
       "3      0.439216  0.564706  0.815686  0.137255  0.592157  0.164706   \n",
       "4      0.560784  0.443137  0.878431  0.125490  0.282353  0.294118   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "16533  0.796078  0.976471  0.129412  0.470588  0.396078  0.874510   \n",
       "16534  0.839216  0.925490  0.133333  0.396078  0.337255  0.866667   \n",
       "16535  0.796078  0.952941  0.137255  0.482353  0.329412  0.796078   \n",
       "16536  0.627451  0.968627  0.725490  0.596078  0.376471  0.807843   \n",
       "16537  0.866667  0.976471  0.192157  0.466667  0.396078  0.796078   \n",
       "\n",
       "               label  \n",
       "0      silky_terrier  \n",
       "1      silky_terrier  \n",
       "2      silky_terrier  \n",
       "3      silky_terrier  \n",
       "4      silky_terrier  \n",
       "...              ...  \n",
       "16533  tan_coonhound  \n",
       "16534  tan_coonhound  \n",
       "16535  tan_coonhound  \n",
       "16536  tan_coonhound  \n",
       "16537  tan_coonhound  \n",
       "\n",
       "[16538 rows x 2501 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>tan_coonhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4042 rows × 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.827451  0.678431  0.392157  0.776471  1.000000  0.066667  0.298039   \n",
       "1     0.780392  0.509804  0.376471  0.729412  1.000000  0.070588  0.192157   \n",
       "2     0.835294  0.713726  0.380392  0.709804  1.000000  0.058824  0.250980   \n",
       "3     0.819608  0.709804  0.403922  0.670588  1.000000  0.070588  0.282353   \n",
       "4     0.823529  0.698039  0.368627  0.760784  0.996078  0.062745  0.345098   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4037  0.192157  0.576471  0.800000  1.000000  0.282353  0.745098  0.109804   \n",
       "4038  0.211765  0.541176  0.745098  1.000000  0.235294  0.780392  0.137255   \n",
       "4039  0.447059  0.435294  0.752941  1.000000  0.227451  0.219608  0.262745   \n",
       "4040  0.517647  0.368627  0.717647  1.000000  0.137255  0.309804  0.250980   \n",
       "4041  0.666667  0.407843  0.737255  1.000000  0.074510  0.309804  0.054902   \n",
       "\n",
       "             7         8         9  ...      2491      2492      2493  \\\n",
       "0     0.003922  0.443137  0.768627  ...  0.121569  0.894118  0.478431   \n",
       "1     0.266667  0.780392  1.000000  ...  0.050980  0.792157  0.588235   \n",
       "2     0.615686  0.635294  0.925490  ...  0.117647  0.800000  0.654902   \n",
       "3     0.674510  0.658824  0.686275  ...  0.129412  0.690196  0.415686   \n",
       "4     0.588235  0.635294  0.039216  ...  0.031373  0.768627  0.490196   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4037  0.725490  0.568627  0.321569  ...  0.741176  0.835294  0.584314   \n",
       "4038  0.356863  0.600000  0.184314  ...  0.529412  0.898039  0.635294   \n",
       "4039  0.545098  0.525490  0.992157  ...  0.725490  0.690196  0.709804   \n",
       "4040  0.662745  0.654902  0.823529  ...  0.654902  0.819608  0.635294   \n",
       "4041  0.835294  0.780392  0.517647  ...  0.862745  0.458824  0.815686   \n",
       "\n",
       "          2494      2495      2496      2497      2498      2499  \\\n",
       "0     0.768627  0.000000  0.078431  0.090196  0.607843  0.278431   \n",
       "1     0.682353  0.000000  0.109804  0.054902  0.635294  0.356863   \n",
       "2     0.678431  0.000000  0.125490  0.078431  0.866667  0.141176   \n",
       "3     0.560784  0.000000  0.054902  0.062745  0.756863  0.298039   \n",
       "4     0.670588  0.000000  0.125490  0.047059  0.815686  0.121569   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "4037  0.000000  0.066667  0.105882  0.819608  0.945098  0.125490   \n",
       "4038  0.000000  0.098039  0.074510  0.168627  0.901961  0.125490   \n",
       "4039  0.000000  0.086275  0.172549  0.192157  0.262745  0.133333   \n",
       "4040  0.000000  0.145098  0.223529  0.254902  0.407843  0.129412   \n",
       "4041  0.000000  0.215686  0.168627  0.537255  0.231373  0.125490   \n",
       "\n",
       "              label  \n",
       "0     silky_terrier  \n",
       "1     silky_terrier  \n",
       "2     silky_terrier  \n",
       "3     silky_terrier  \n",
       "4     silky_terrier  \n",
       "...             ...  \n",
       "4037  tan_coonhound  \n",
       "4038  tan_coonhound  \n",
       "4039  tan_coonhound  \n",
       "4040  tan_coonhound  \n",
       "4041  tan_coonhound  \n",
       "\n",
       "[4042 rows x 2501 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE THE PROPOSAL TIMELINE ACCORDING TO WHAT HAS ACTUALLY HAPPENED AND HOW IT HAS EFFECTED YOUR FUTURE PLANS\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
